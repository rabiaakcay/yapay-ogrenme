{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "awful-separate",
   "metadata": {},
   "source": [
    "## Röntgen Resimlerinden COVID-19 Tahmini\n",
    "\n",
    "Birden çok veri kaynağından toplanan . Veri kaynaklarının özetine https://github.com/lindawangg/COVID-Net/blob/master/docs/COVIDx.md adresinden ulaşılabilir. Bu çalıştay için resimler küçültüldü ve eğitim ve test kümeleri sınıf oranlarını korumak için bir miktar değiştirildi.\n",
    "\n",
    "Bu çalıştayda göğüs röntgen resimlerinden, normal, covid olmaya zatürre ve covid-19 tespiti çalışması yapılacaktır. Tahmin için Evrişimsel Sinir Ağları (Convolutional Neural Network) yaratılacak ve eğitilecektir. Kullanılan resimler bir çok veri kaynağından toplanmıştır. Veri kaynaklarının özetine https://github.com/lindawangg/COVID-Net/blob/master/docs/COVIDx.md adresinden ulaşılabilir. Bu çalıştay için resimler küçültülmüş ve eğitim ve test kümeleri sınıf oranlarını korumak için bir miktar değiştirilmiştir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gereken kütüphaneler\n",
    "import os, glob, time, random\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.keras.layers as Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genel olarak yardımcı fonksiyonlar\n",
    "def setupMatplotLib():\n",
    "    plt.rc('figure', figsize=(10,7))\n",
    "    plt.rc('font', size=14)\n",
    "    plt.rc('axes', titlesize=18)     # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=18)     # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=14)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=14)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=12)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=20)   # fontsize of the figure title\n",
    "setupMatplotLib()\n",
    "\n",
    "def plot_history(histories, vertical=False, otherkey='accuracy'):\n",
    "    plt.rc('figure', figsize=(14,8))\n",
    "    if vertical:\n",
    "        p,r = 2,1\n",
    "    else:\n",
    "        p,r = 1,2 \n",
    "    anyPlots = False\n",
    "    k=1\n",
    "    for name, history in histories:\n",
    "        if 'val_loss' in history.history.keys():\n",
    "            anyPlots = True\n",
    "            \n",
    "            ax = plt.subplot(p,r,1)\n",
    "            val = ax.plot(history.epoch, history.history['val_loss'],\n",
    "                           '--', label=name.title()+' Val')\n",
    "            ax.plot(history.epoch, history.history['loss'], color=val[0].get_color(),\n",
    "                     label=name.title()+' Train')\n",
    "        elif 'loss' in history.history.keys():\n",
    "            anyPlots = True\n",
    "            \n",
    "            ax = plt.subplot(p,r,1)\n",
    "            ax.plot(history.epoch, history.history['loss'], label=name.title()+' Train')\n",
    "            \n",
    "        if 'val_' + otherkey in history.history.keys():\n",
    "            k = 2\n",
    "            anyPlots = True\n",
    "            \n",
    "            ax = plt.subplot(p,r,2)\n",
    "            val = ax.plot(history.epoch, history.history['val_' + otherkey],\n",
    "                           '--', label=name.title()+' Val')\n",
    "            ax.plot(history.epoch, history.history[otherkey], color=val[0].get_color(),\n",
    "                     label=name.title()+' Train')\n",
    "        elif otherkey in history.history.keys():\n",
    "            k = 2\n",
    "            anyPlots = True\n",
    "            \n",
    "            ax = plt.subplot(p,r,2)\n",
    "            ax.plot(history.epoch, history.history[otherkey], label=name.title()+' Train')\n",
    "        plt.rc('figure', figsize=(10,7))\n",
    "\n",
    "    if anyPlots:\n",
    "        for i in range(1,k+1):\n",
    "            if i == 1:\n",
    "                key = histories[0][1].model.loss\n",
    "            else:\n",
    "                key = otherkey\n",
    "            ax = plt.subplot(p,r,i)\n",
    "            ax.set_xlabel('Epochs')\n",
    "            ax.set_ylabel(key.replace('_',' ').title())\n",
    "            ax.legend()\n",
    "        plt.tight_layout()\n",
    "        \n",
    "def plotClassCounts(countDict):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.bar(range(len(countDict)), countDict.values())\n",
    "    plt.xticks(range(len(countDict)),countDict.keys())\n",
    "    plt.ylabel('Sayılar')\n",
    "    plt.xlabel('Sınıflar')\n",
    "\n",
    "# Klasördeki bütün dosyalar ersim diye varsayıyoruz\n",
    "def plotRandomImages(path):\n",
    "    classNames = ['COVID-19','normal','pneumonia']\n",
    "    images = []\n",
    "    for i, cn in enumerate(classNames):\n",
    "        imageNames = imagesC19 = os.listdir(os.path.join(path,cn))\n",
    "        filepath = random.choice(imageNames)\n",
    "        images.append(Image.open(os.path.join(path,cn,filepath)))\n",
    "    plt.figure(figsize=(18,6))\n",
    "    for i in range(3):\n",
    "        plt.subplot(1,3,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i], cmap=plt.cm.binary_r)\n",
    "        plt.xlabel(classNames[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim ve validasyıon kümesi aynı rassal çekirdek ile başlaması için\n",
    "seed = int(time.time())\n",
    "\n",
    "# Elimizdeki resimler 256x256. Eğitim biraz daha hızlı olsun diye 128x128 olarak eğitiyoruz\n",
    "imsize = (128, 128)\n",
    "\n",
    "# Veriyi değişik dönüşümler ile değiştirip değiştirmeyeceğimiz\n",
    "# Genelde veri az ise bu işe yarar ancak bu problem için şart değil gibi gözüküyor\n",
    "augment = False \n",
    "\n",
    "datadir = 'data'\n",
    "\n",
    "if augment:\n",
    "    \n",
    "    # Hafızaya sığacak kadar seçiyoruz, sizin kullandığınız yerde farklı seçmek gerekebilir\n",
    "    batch_size = 256\n",
    "    \n",
    "    traingGen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rotation_range=3,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        rescale=1/255.,\n",
    "        validation_split=0.2,\n",
    "        dtype='float16'\n",
    "    )\n",
    "    \n",
    "    testGen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1/255.,\n",
    "        dtype='float16'\n",
    "    ) \n",
    "    \n",
    "    trainData = traingGen.flow_from_directory(\n",
    "        directory = os.path.join(datadir, 'train'),\n",
    "        color_mode=\"grayscale\",\n",
    "        batch_size=batch_size,\n",
    "        target_size=imsize,\n",
    "        shuffle=True,\n",
    "        subset='training',\n",
    "        seed = seed,\n",
    "        class_mode=\"sparse\"\n",
    "    )\n",
    "    \n",
    "    valData = traingGen.flow_from_directory(\n",
    "        directory = os.path.join(datadir, 'train'),\n",
    "        color_mode=\"grayscale\",\n",
    "        batch_size=batch_size,\n",
    "        target_size=imsize,\n",
    "        shuffle=True,\n",
    "        subset='validation',\n",
    "        seed = seed,\n",
    "        class_mode=\"sparse\"\n",
    "    )\n",
    "    \n",
    "    testData = testGen.flow_from_directory(\n",
    "        directory = os.path.join(datadir, 'test'),\n",
    "        color_mode=\"grayscale\",\n",
    "        batch_size=batch_size,\n",
    "        target_size=imsize,\n",
    "        class_mode=\"sparse\",\n",
    "        shuffle = False\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # Hafızaya sığacak kadar seçiyoruz, sizin kullandığınız yerde farklı seçmek gerekebilir\n",
    "    batch_size = 128\n",
    "    \n",
    "    trainData = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        directory = os.path.join(datadir, 'train'),\n",
    "        color_mode=\"grayscale\",\n",
    "        batch_size=batch_size,\n",
    "        image_size=imsize,\n",
    "        shuffle=True,\n",
    "        validation_split=0.2,\n",
    "        subset='training',\n",
    "        seed = seed\n",
    "    )\n",
    "\n",
    "    valData = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        directory = os.path.join(datadir, 'train'),\n",
    "        color_mode=\"grayscale\",\n",
    "        batch_size=batch_size,\n",
    "        image_size=imsize,\n",
    "        shuffle=True,\n",
    "        validation_split=0.2,\n",
    "        subset='validation',\n",
    "        seed = seed\n",
    "    )\n",
    "\n",
    "    testData = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        directory = os.path.join(datadir, 'test'),\n",
    "        color_mode=\"grayscale\",\n",
    "        batch_size=batch_size,\n",
    "        image_size=imsize,\n",
    "        shuffle = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-princess",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sınıf sayılarına bakalım\n",
    "\n",
    "# veriden saymak isteseydik ama sayırları bildiğimiz için geçiyoruz\n",
    "#if augment:\n",
    "#    yTrain = trainData.classes\n",
    "#    yTest  = testData.classes\n",
    "#else:\n",
    "#    yTrain = np.concatenate([y for x, y in trainData], axis=0)\n",
    "#    yTest  = np.concatenate([y for x, y in testData], axis=0)\n",
    "\n",
    "# Eğitim ve test kümeleri veriden 90-10 olarak ayrıldı. Eğitirken %90'nın %20'sini de validasyon olarak ayıracağız.\n",
    "counts = {'train':{'COVID-19':1593,'normal':7966,'pneumonia':5462},\n",
    "          'test': {'COVID-19':177, 'normal': 885,'pneumonia': 607}}\n",
    "\n",
    "# Sınıf oranları, görüleceği üzere eşit değiller\n",
    "train_ratios = np.array(list(counts['train'].values()))/sum(counts['train'].values())\n",
    "\n",
    "print('Sınıf oranları:',train_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotClassCounts(counts['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-mineral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rastgele örneklere bakalım\n",
    "plotRandomImages('data/train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-pipeline",
   "metadata": {},
   "source": [
    "Artık sıra modeli kurmaya geldi. Başlangıç için çok ufak bir model veriyoruz ancak bu yeterli değil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-victor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bunu geliştirmek size kalmış!\n",
    "def baseCnnClassifier(optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Tipik bir evrişimsel grup\n",
    "    model.add(Layers.Conv2D(filters = 16, kernel_size=(5,5), strides = 1, padding='same'))\n",
    "    model.add(Layers.Activation('relu'))\n",
    "    model.add(Layers.Conv2D(filters = 16, kernel_size=(5,5), strides = 1, padding='same'))\n",
    "    model.add(Layers.Activation('relu')) \n",
    "    model.add(Layers.BatchNormalization()) \n",
    "    model.add(Layers.MaxPool2D(pool_size=(2,2),strides=2))\n",
    "    \n",
    "    model.add(Layers.Conv2D(filters=32,kernel_size=(3,3), strides = 1, padding='same'))\n",
    "    model.add(Layers.Activation('relu'))\n",
    "    model.add(Layers.Conv2D(filters=32,kernel_size=(3,3), strides = 1, padding='same'))\n",
    "    model.add(Layers.Activation('relu'))\n",
    "    model.add(Layers.BatchNormalization())\n",
    "    model.add(Layers.MaxPool2D(pool_size=(2,2),strides=2))\n",
    "    \n",
    "    # Çıktı katmanına bağlamak için düzleştiriyoruz\n",
    "    model.add(Layers.GlobalAveragePooling2D())\n",
    "    \n",
    "    model.add(Layers.Dense(3,activation='softmax', dtype='float32'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeli yaratalım\n",
    "baseModel = baseCnnClassifier(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005))\n",
    "\n",
    "# Aşırı-uyum yaptığı durumda erkenden bitirmek için\n",
    "earlyStop = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "\n",
    "# Validasyon kümemize göre performansu en iyi olan modeli kaydedelim\n",
    "modelSave = keras.callbacks.ModelCheckpoint('./checkpoint',monitor='val_accuracy', \n",
    "                                            save_best_only=True, save_weights_only=True,\n",
    "                                            mode='max',)\n",
    "epochs = 20\n",
    "\n",
    "baseHist = baseModel.fit(trainData,\n",
    "                         epochs = epochs, verbose = 1,\n",
    "                         # Validasyon verisine göre model seçip eğitimi durduracağız\n",
    "                         validation_data=valData,\n",
    "                         callbacks = [earlyStop, modelSave],                         \n",
    "                         # Sınıf oranları eşit değildi, COVID arada kaynamasın diye onun ağırlığını arttırıyoruz\n",
    "                         class_weight = {0: 4, 1: 1, 2: 1}\n",
    "                        )\n",
    "\n",
    "baseModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-utilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history([('COVID',baseHist)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En iyi validasyon sonucunu veren ağırlıkları yüklüyoruz\n",
    "baseModel.load_weights('./checkpoint')\n",
    "#print('Eğitim performansı', baseModel.evaluate(trainData))\n",
    "\n",
    "# Eğitimde ve model seçiminde kullanmadığımız bir küme ile test ediyoruz\n",
    "print('Test performansı', baseModel.evaluate(testData))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-pilot",
   "metadata": {},
   "source": [
    "Sonuçlara biraz daha detaylı bakalım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-papua",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix, ConfusionMatrixDisplay\n",
    "ypred = np.argmax(baseModel.predict(testData), axis=-1)\n",
    "if augment:\n",
    "    ytrue = testData.classes\n",
    "else:\n",
    "    ytrue = np.concatenate([y for x, y in testData], axis=0)\n",
    "print(classification_report(ytrue, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(ytrue, ypred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['COVID-19','Normal','Pneumonia'])\n",
    "disp.plot(cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-warrior",
   "metadata": {},
   "source": [
    "Buradan nereye gidebilirsiniz:\n",
    "* Daha ileri mimariler (bu problem için örnek: https://arxiv.org/abs/2003.09871)\n",
    "* Tıbbi görüntülerde bölütleme (segmentasyon)\n",
    "* Başka tıbbi görüntüler (örn: göğüs tomografisi)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.mnightly-2021-02-12-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:mnightly-2021-02-12-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
